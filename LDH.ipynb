{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import spm1d\n",
    "import itertools\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sio\n",
    "import scipy.io as sio\n",
    "import multiprocessing as mp\n",
    "\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "from scipy.signal import savgol_filter\n",
    "from joblib import Parallel, delayed\n",
    "from lolviz import *\n",
    "from pylab import *\n",
    "\n",
    "print('libs imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "def fitF(data):\n",
    "    datalist = []\n",
    "    for c in range(1,180):\n",
    "        strain = data.Strain[data.Cycle == c+0.5]\n",
    "        stress = data.Stress[data.Cycle == c+0.5]\n",
    "        if strain.empty:\n",
    "            datalist.append([np.nan,np.nan,np.nan,np.nan])\n",
    "        else:\n",
    "            fit = np.polyfit(strain-min(strain), np.log(stress), 1, w=np.sqrt(stress),full = True)\n",
    "            datalist.append([c,fit[0][0],exp(fit[0][1]),fit[1][0]])\n",
    "    output = pd.DataFrame(datalist, columns=['Cycle','One','Two','Residual'])\n",
    "    averages = [output.One.mean(),output.Two.mean(),output.Residual.mean(),output.One.std(),output.Two.std(),output.Residual.std()]\n",
    "    return output, averages\n",
    "\n",
    "def Average(lst): \n",
    "    return sum(lst) / len(lst) \n",
    "\n",
    "print('functinos defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw data from MTS files and insert into dataframe\n",
    "parameters = pd.read_excel(os.getcwd() + '/Data/Parameters.xlsx')\n",
    "fitlist = []\n",
    "datalist = []\n",
    "exp1Alist = []\n",
    "exp2Alist = []\n",
    "residualAlist = []\n",
    "exp1SDlist = []\n",
    "exp2SDlist = []\n",
    "residualSDlist = []\n",
    "for folder,height,area in zip(parameters.key,parameters.height,parameters.area):\n",
    "    data = pd.read_csv(os.getcwd() + '/Data/'+ folder + '/DAQ- Time, â€¦ - (Timed).txt',sep='\\t',skiprows=[0,1,2,3,4,5,7])\n",
    "    data.columns = ['Time', 'Displacement', 'Force', 'Error','Cycle']\n",
    "    minX = max(data.Displacement[data.Cycle == 0.5])\n",
    "    Displacement_Norm = []\n",
    "    Strain = []\n",
    "    Stress = []\n",
    "    Strain_True = []\n",
    "    Stress_True = []\n",
    "    for x,y in zip(data.Displacement,data.Force):\n",
    "        Displacement_Norm.append(x-minX)\n",
    "        newx = -(x-minX)/height\n",
    "        Strain.append(newx)\n",
    "        newy = -y/area\n",
    "        Stress.append(newy)\n",
    "        Strain_True.append(-np.log(1-newx))\n",
    "        Stress_True.append(newy*(1-newx))\n",
    "    data.insert(5,\"Displacement_Norm\",Displacement_Norm)\n",
    "    data.insert(6,\"Strain\",Strain)\n",
    "    data.insert(7,\"Stress\",Stress)\n",
    "    data.insert(8,\"Strain_True\",Strain_True)\n",
    "    data.insert(9,\"Stress_True\",Stress_True)\n",
    "    datalist.append(data)\n",
    "    fit, averages = fitF(data)\n",
    "    exp1Alist.append(averages[0])\n",
    "    exp2Alist.append(averages[1])\n",
    "    residualAlist.append(averages[2])\n",
    "    exp1SDlist.append(averages[3])\n",
    "    exp2SDlist.append(averages[4])\n",
    "    residualSDlist.append(averages[5])\n",
    "    fitlist.append(fit)\n",
    "parameters.insert(7,\"Data\",datalist)\n",
    "parameters.insert(8,\"ExpAvg\",exp1Alist)\n",
    "parameters.insert(9,\"OffsetAvg\",exp2Alist)\n",
    "parameters.insert(10,\"ResidualAvg\",residualAlist)\n",
    "parameters.insert(11,\"ExpSD\",exp1SDlist)\n",
    "parameters.insert(12,\"OffsetSD\",exp2SDlist)\n",
    "parameters.insert(13,\"ResidualSD\",residualSDlist)\n",
    "parameters.insert(14,\"Fit\",residualSDlist)\n",
    "\n",
    "parameters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = pd.concat([parameters['key'], parameters['state'],parameters['timepoint'],parameters['sample'],parameters['state name'],\n",
    "                   parameters['ExpAvg'], parameters['OffsetAvg'],parameters['ResidualAvg'],parameters['ExpSD'],parameters['OffsetSD'],parameters['ResidualSD']],\n",
    "                   axis=1,\n",
    "                   keys=['key','state','timepoint','sample','state name','ExpAvg','OffsetAvg','ResidualAvg','ExpSD','OffsetSD','ResidualSD'])\n",
    "export.to_excel('output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#polynomial fit\n",
    "# timepoints = [0,1,2,3,4]\n",
    "# statenames = ['intact','damaged','repaired']\n",
    "# samples = [11,12,13,14,15,21,22,23,24,25,26,31,32,33,41,42,43,44,45,51,52,53,54,55]\n",
    "# results = []\n",
    "# for sample in samples:\n",
    "#     for timepoint in timepoints:\n",
    "#         if timepoint > 0:\n",
    "#             before = parameters.Fit[(parameters['timepoint']==timepoint) & (parameters['sample']==sample)]\n",
    "#             after = parameters.Fit[(parameters['timepoint']==(timepoint-1)) & (parameters['sample']==sample)]\n",
    "#             state = parameters['state name'][(parameters['timepoint']==timepoint) & (parameters['sample']==sample)].values[0]\n",
    "#             valC = []\n",
    "#             for valB,valA in zip(before,after):\n",
    "#                 valC.append((valB.Three-valA.Three)/valA.Three)\n",
    "#             results.append([sample,timepoint,state] + valC[0].values.tolist())\n",
    "# listofnames = ['sample','timepoint','state']+ [n for n in range(179)]\n",
    "# threedf = pd.DataFrame(results,columns=listofnames)\n",
    "\n",
    "timepoints = [0,1,2,3,4]\n",
    "statenames = ['intact','damaged','repaired']\n",
    "samples = [11,12,13,14,15,21,22,23,24,25,26,31,32,33,41,42,43,44,45,51,52,53,54,55]\n",
    "results = []\n",
    "for sample in samples:\n",
    "    for timepoint in timepoints:\n",
    "        if timepoint > 0:\n",
    "            after = parameters.Fit[(parameters['timepoint']==timepoint) & (parameters['sample']==sample)]\n",
    "            before = parameters.Fit[(parameters['timepoint']==(timepoint-1)) & (parameters['sample']==sample)]\n",
    "            state = parameters['state name'][(parameters['timepoint']==timepoint) & (parameters['sample']==sample)].values[0]\n",
    "            valC = []\n",
    "            for valB,valA in zip(after,before):\n",
    "                valC.append((valB.Two-valA.Two)/valA.Two)\n",
    "            results.append([sample,timepoint,state] + valC[0].values.tolist())\n",
    "listofnames = ['sample','timepoint','state']+ [n for n in range(179)]\n",
    "twodf = pd.DataFrame(results,columns=listofnames)\n",
    "\n",
    "timepoints = [0,1,2,3,4]\n",
    "statenames = ['intact','damaged','repaired']\n",
    "samples = [11,12,13,14,15,21,22,23,24,25,26,31,32,33,41,42,43,44,45,51,52,53,54,55]\n",
    "results = []\n",
    "for sample in samples:\n",
    "    for timepoint in timepoints:\n",
    "        if timepoint > 0:\n",
    "            after = parameters.Fit[(parameters['timepoint']==timepoint) & (parameters['sample']==sample)]\n",
    "            before = parameters.Fit[(parameters['timepoint']==(timepoint-1)) & (parameters['sample']==sample)]\n",
    "            state = parameters['state name'][(parameters['timepoint']==timepoint) & (parameters['sample']==sample)].values[0]\n",
    "            valC = []\n",
    "            for valB,valA in zip(after,before):\n",
    "                valC.append((valB.One-valA.One)/valA.One)\n",
    "            results.append([sample,timepoint,state] + valC[0].values.tolist())\n",
    "listofnames = ['sample','timepoint','state']+ [n for n in range(179)]\n",
    "onedf = pd.DataFrame(results,columns=listofnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single variable analysis\n",
    "timepoint = 1\n",
    "state = ['intact','damaged']\n",
    "length = range(1,179)\n",
    "samplesN = len(threedf[0][(threedf.timepoint == timepoint) & (threedf.state == state[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate analysis\n",
    "timepoint = 1\n",
    "state = ['intact','damaged']\n",
    "length = range(1,179)\n",
    "samplesN = len(threedf[0][(threedf.timepoint == timepoint) & (threedf.state == state[0])])\n",
    "\n",
    "YA = np.zeros(shape=(samplesN,len(length),2))\n",
    "for m in range(samplesN):\n",
    "    for n,n1 in zip(length,range(len(length))):\n",
    "        YA[m,n1] = np.array([onedf[n][(onedf.timepoint == timepoint) & (onedf.state == state[0])].values[m],\n",
    "                             twodf[n][(twodf.timepoint == timepoint) & (twodf.state == state[0])].values[m]])\n",
    "#                             threedf[n][(threedf.timepoint == timepoint) & (threedf.state == state[0])].values[m]])\n",
    "        \n",
    "YB = np.zeros(shape=(samplesN,len(length),2))\n",
    "for m in range(samplesN):\n",
    "    for n,n1 in zip(length,range(len(length))):\n",
    "        YB[m,n1] = np.array([onedf[n][(onedf.timepoint == timepoint) & (onedf.state == state[1])].values[m],\n",
    "                             twodf[n][(twodf.timepoint == timepoint) & (twodf.state == state[1])].values[m]])\n",
    "#                             threedf[n][(threedf.timepoint == timepoint) & (threedf.state == state[1])].values[m]])\n",
    "\n",
    "\n",
    "\n",
    "#(1) Conduct test:\n",
    "alpha        = 0.05\n",
    "T2           = spm1d.stats.hotellings_paired(YA, YB)\n",
    "T2i          = T2.inference(0.05)\n",
    "print(T2i)\n",
    "\n",
    "\n",
    "#(2) Plot:\n",
    "plt.close('all')\n",
    "rcParams[\"figure.figsize\"] = [20, 10] \n",
    "ax0     = plt.subplot(221)\n",
    "ax1     = plt.subplot(222)\n",
    "ax3     = plt.subplot(224)\n",
    "## plot SPM results:\n",
    "ax0.plot(YA[:,:,0].T, 'k', label='slow')\n",
    "ax0.plot(YB[:,:,0].T, 'r', label='fast')\n",
    "ax1.plot(YA[:,:,1].T, 'k')\n",
    "ax1.plot(YB[:,:,1].T, 'r')\n",
    "T2i.plot(ax=ax3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for timepoint in timepoints:\n",
    "    if timepoint > 0:\n",
    "        for state in statenames:\n",
    "            vals = []\n",
    "            for n in range(179):\n",
    "                vals.append(threedf[n][(threedf.timepoint == timepoint) & (threedf.state == state)].mean())\n",
    "            results.append([timepoint,state] + vals)\n",
    "listofnames = ['timepoint','state'] + [n for n in range(179)]\n",
    "three_results = pd.DataFrame(results,columns = listofnames)\n",
    "three_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for timepoint in timepoints:\n",
    "    if timepoint > 0:\n",
    "        for state in statenames:\n",
    "            vals = []\n",
    "            for n in range(179):\n",
    "                vals.append(twodf[n][(twodf.timepoint == timepoint) & (twodf.state == state)].mean())\n",
    "            results.append([timepoint,state] + vals)\n",
    "listofnames = ['timepoint','state'] + [n for n in range(179)]\n",
    "two_results = pd.DataFrame(results,columns = listofnames)\n",
    "two_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for timepoint in timepoints:\n",
    "    if timepoint > 0:\n",
    "        for state in statenames:\n",
    "            vals = []\n",
    "            for n in range(179):\n",
    "                vals.append(onedf[n][(onedf.timepoint == timepoint) & (onedf.state == state)].mean())\n",
    "            results.append([timepoint,state] + vals)\n",
    "listofnames = ['timepoint','state'] + [n for n in range(179)]\n",
    "one_results = pd.DataFrame(results,columns = listofnames)\n",
    "one_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplot1 = []\n",
    "toplot2 = []\n",
    "toplot3 = []\n",
    "for n in range (2,179):\n",
    "    toplot1.append(three_results[(three_results.state == 'intact') & (three_results.timepoint == 4)][n].values[0])\n",
    "    toplot2.append(three_results[(three_results.state == 'damaged') & (three_results.timepoint == 4)][n].values[0])\n",
    "    toplot3.append(three_results[(three_results.state == 'repaired') & (three_results.timepoint == 4)][n].values[0])\n",
    "plot(range(2,179),toplot1)\n",
    "plot(range(2,179),toplot2)\n",
    "plot(range(2,179),toplot3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [15, 10]\n",
    "for name,sample in zip(parameters.timepoint[(parameters['state name'] == 'intact')],parameters.Fit[(parameters['state name'] == 'intact')]):\n",
    "    plt.scatter(sample.Cycle,sample.Three,s=1,label=name)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strain0 = parameters.Data[0].Strain_True[parameters.Data[0].Cycle == 1.5] - min(parameters.Data[0].Strain_True[parameters.Data[0].Cycle == 1.5])\n",
    "#plt.scatter(strain0,output[0][1](strain0),color='red')\n",
    "#plt.scatter(strain0,parameters.Data[0].Stress_True[parameters.Data[0].Cycle == 1.5],color='blue')\n",
    "strain1 = parameters.Data[0].Strain_True[parameters.Data[0].Cycle == 140.5]-min(parameters.Data[0].Strain_True[parameters.Data[0].Cycle == 140.5])\n",
    "plt.scatter(strain1,output[139][1](strain1),color='red')\n",
    "plt.scatter(strain1,parameters.Data[0].Stress_True[parameters.Data[0].Cycle == 140.5],color='blue')\n",
    "strain2 = parameters.Data[0].Strain_True[parameters.Data[0].Cycle == 130.5]-min(parameters.Data[0].Strain_True[parameters.Data[0].Cycle == 130.5])\n",
    "plt.scatter(strain2,output[129][1](strain2),color='red')\n",
    "plt.scatter(strain2,parameters.Data[0].Stress_True[parameters.Data[0].Cycle == 130.5],color='blue')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
